# ğŸš€ Smart CDN with GenAI Control Plane

A production-inspired Content Delivery Network (CDN) with AI-driven optimization, explainability, and smart prefetching. This project demonstrates **how real CDNs like Cloudflare and Akamai separate the data plane (fast) from the control plane (smart)**.

## ğŸ¯ Core Philosophy

### âŒ GenAI is NOT in the request path

### âœ… GenAI lives in the **Control Plane**

```
DATA PLANE (Fast)
Client â†’ Load Balancer â†’ Edge Cache â†’ Origin

CONTROL PLANE (Smart)
Logs â†’ GenAI â†’ Recommendations â†’ Config Updates
```

This mirrors **real CDN architectures** where AI analyzes patterns asynchronously without adding latency to user requests.

---

## ğŸ—ï¸ Architecture

```
Clients
   â†“
Load Balancer (port 8080)
   â†“
Edge Servers (edge1, edge2) - Cache + Logging
   â†“
Origin Server - Static Content

   â•‘ (Async Analytics)
   â•‘
   â–¼
Monitoring Service (port 8001) - Log Aggregation
   â†“
GenAI Engine (port 8000) - AI Analysis
   â€¢ TTL Optimizer
   â€¢ Prefetch Analyzer
   â€¢ Explainability Engine
   â†“
Configuration Updates
   â†“
API Gateway (port 8888) - Unified Interface
```

---

## ğŸ¥‡ Three Core Features

### 1. AI-Driven TTL Optimization (Primary Feature)

**Problem:** Static TTLs don't adapt to traffic patterns.

**Solution:** GenAI analyzes request patterns and recommends optimal cache durations.

**Inputs to AI:**

- Request frequency per file
- Cache hit/miss ratio
- File type (image, CSS, JS, HTML)
- Time-based traffic spikes

**AI Output Example:**

```json
{
  "file": "/promo/banner.jpg",
  "recommended_ttl": 21600,
  "ttl_human": "6h",
  "reason": "Traffic increased 5Ã— in last 10 mins - high-read, low-change content",
  "stats": {
    "total_requests": 127,
    "cache_hit_ratio": "78.74%",
    "file_type": "image"
  }
}
```

**Why This Is Smart:**

- TTL becomes **adaptive** instead of static
- Reduces origin load during traffic spikes
- Improves cache efficiency automatically

---

### 2. Explainability Layer (Uniqueness Booster)

**Problem:** CDN decisions are opaque black boxes.

**Solution:** Every CDN decision has a human-readable explanation.

**What We Explain:**

- Why cache HIT or MISS happened
- Why a particular edge served the request
- Why TTL was increased/decreased

**Example Explanation:**

```json
{
  "request_path": "/index.html",
  "edge_server": "edge1",
  "cache_status": "MISS",
  "ttl": 300,
  "summary": "Cache MISS: File '/index.html' requested for first time in this region, fetched from origin",
  "explanations": {
    "cache": "First-time request - not yet cached",
    "routing": "Routed to edge1 (closest to client location)",
    "ttl": "TTL set to 5 minutes - HTML may update frequently"
  }
}
```

**Where It Lives:**

- Stored in logs
- Exposed via API: `GET /api/explainability/recent`
- Available as debug headers

**Interview Gold:**

> "I added an explainability layer to make CDN decisions transparent and debuggable, turning a black box into a glass box."

---

### 3. Smart Prefetching (Performance Multiplier)

**Problem:** Users request related assets sequentially, causing delays.

**Solution:** AI detects patterns and prefetches related assets proactively.

**Pattern Detection:**

```
Observed Pattern:
/index.html â†’ /style.css â†’ /script.js

AI Recommendation:
When /index.html is requested, prefetch /style.css and /script.js
```

**Output Example:**

```json
{
  "trigger_file": "/index.html",
  "prefetch_files": ["/style.css", "/script.js", "/logo.png"],
  "confidence": 0.9,
  "reason": "Pattern detected: /index.html is frequently followed by 3 assets"
}
```

**Why This Is Safe:**

- Prefetch happens **after** serving main request (non-blocking)
- Only caches predicted assets
- TTL rules still apply

---

## ğŸ“¦ Component Responsibilities

| Component              | Responsibility                             |
| ---------------------- | ------------------------------------------ |
| **Edge Servers**       | Cache content, execute prefetch, send logs |
| **Load Balancer**      | Distribute traffic across edge servers     |
| **Origin Server**      | Source of truth for content                |
| **Monitoring Service** | Aggregate logs from all edge servers       |
| **GenAI Engine**       | Analyze patterns, generate recommendations |
| **API Gateway**        | Unified interface for all services         |

---

## ğŸš€ Getting Started

### Prerequisites

- Docker
- Docker Compose
- 8GB RAM minimum
- Ports 8000, 8001, 8080, 8888 available

### Quick Start

1. **Clone and navigate to project:**

```bash
cd cdn-simulator
```

2. **Build and start all services:**

```bash
docker-compose up --build
```

3. **Access the dashboard:**

```
http://localhost:8888
```

You'll see an interactive dashboard with all features and endpoints!

4. **Test the CDN:**

```bash
# Make requests through the CDN
curl -i http://localhost:8080/hello.txt
curl -i http://localhost:8080/index.html
curl -i http://localhost:8080/style.css
```

5. **View AI recommendations:**

```bash
# TTL recommendations
curl http://localhost:8888/api/recommendations/ttl

# Prefetch recommendations
curl http://localhost:8888/api/recommendations/prefetch

# Recent explanations
curl http://localhost:8888/api/explainability/recent
```

---

## ğŸ” Observe Smart Behavior

### First Request (Cache MISS)

```bash
curl -i http://localhost:8080/hello.txt
```

Response headers:

```
X-Cache-Status: MISS
X-Edge-Server: edge1
X-Cache-TTL: 60s
```

**Explanation:** First request, fetched from origin and cached.

### Second Request (Cache HIT)

```bash
curl -i http://localhost:8080/hello.txt
```

Response headers:

```
X-Cache-Status: HIT
X-Edge-Server: edge2
X-Cache-TTL: 60s
```

**Explanation:** Served from edge cache (much faster!).

### After Multiple Requests (AI Optimization)

After making 20+ requests:

```bash
curl http://localhost:8888/api/recommendations/ttl | jq
```

Output:

```json
{
  "total_rules": 3,
  "recommendations": {
    "/hello.txt": {
      "ttl": 3600,
      "ttl_human": "1h",
      "reason": "High traffic (47 requests) - increased TTL for better cache efficiency | Low cache hit ratio (34.04%) - increasing TTL"
    }
  }
}
```

**AI detected high traffic and optimized TTL automatically!**

---

## ğŸ“Š Key Endpoints

### Main Dashboard

- **Dashboard:** `http://localhost:8888/`
- **CDN:** `http://localhost:8080/`

### AI Recommendations

- **TTL Recommendations:** `GET http://localhost:8888/api/recommendations/ttl`
- **Prefetch Rules:** `GET http://localhost:8888/api/recommendations/prefetch`
- **Statistics:** `GET http://localhost:8888/api/stats`

### Explainability

- **Recent Explanations:** `GET http://localhost:8888/api/explainability/recent`
- **Specific Request:** `GET http://localhost:8888/api/explainability/{request_id}`

### Monitoring

- **Logs:** `GET http://localhost:8888/api/logs`
- **Config History:** `GET http://localhost:8888/api/config/history`

---

## ğŸ§ª Testing Scenarios

### Scenario 1: Test Cache Behavior

```bash
# Make 10 requests and observe cache status
for i in {1..10}; do
  curl -i http://localhost:8080/hello.txt | grep -E "X-Cache-Status|X-Edge-Server"
done
```

You'll see cache MISses become HITs, and load balancing between edge servers.

### Scenario 2: Trigger TTL Optimization

```bash
# Make 50 requests to trigger AI analysis
for i in {1..50}; do
  curl -s http://localhost:8080/hello.txt > /dev/null
  echo "Request $i sent"
done

# Wait 30 seconds for AI analysis
sleep 30

# Check TTL recommendations
curl http://localhost:8888/api/recommendations/ttl | jq
```

### Scenario 3: Test Prefetch Pattern Detection

```bash
# Simulate user browsing pattern 20 times
for i in {1..20}; do
  curl -s http://localhost:8080/index.html > /dev/null
  curl -s http://localhost:8080/style.css > /dev/null
  curl -s http://localhost:8080/script.js > /dev/null
  sleep 0.5
done

# Wait for AI analysis
sleep 30

# Check prefetch recommendations
curl http://localhost:8888/api/recommendations/prefetch | jq
```

---

## ğŸ› ï¸ Development

### View Logs

```bash
# All services
docker-compose logs -f

# Specific service
docker-compose logs -f genai-engine
docker-compose logs -f edge1
docker-compose logs -f monitoring
```

### Rebuild After Changes

```bash
docker-compose down
docker-compose up --build
```

### Clean Everything

```bash
docker-compose down -v
docker system prune -a
```

### Add More Edge Servers

Edit `docker-compose.yml`:

```yaml
edge3:
  build: ./edge-enhanced
  container_name: edge3
  environment:
    - HOSTNAME=edge3
    - MONITORING_SERVICE_URL=http://monitoring:8001
  depends_on:
    - origin
    - monitoring
  networks:
    - cdn_network
```

Add to `load-balancer/nginx.conf`:

```nginx
upstream edge_pool {
  server edge1:80;
  server edge2:80;
  server edge3:80;
}
```

---

## ğŸ” Safety & Control (Very Important)

### GenAI Does NOT:

âŒ Modify infrastructure automatically  
âŒ Sit in the request path  
âŒ Add latency to user requests  
âŒ Make uncontrolled changes

### GenAI DOES:

âœ… Suggest configurations  
âœ… Explain behavior  
âœ… Optimize over time  
âœ… Operate asynchronously

---

## ğŸ“ Interview-Worthy Talking Points

### 1. Control Plane vs Data Plane

> "I separated the fast path (data plane) from the smart path (control plane), just like production CDNs. GenAI analyzes asynchronously without adding latency."

### 2. Adaptive TTL

> "Instead of static cache durations, my CDN uses AI to adapt TTL based on traffic patterns, reducing origin load and improving efficiency."

### 3. Explainability

> "Every CDN decision has a human-readable explanation. When debugging, you can see exactly why a cache miss occurred or why a particular edge was selected."

### 4. Predictive Prefetching

> "The system learns access patterns and prefetches related assets, reducing perceived latency for users."

### 5. Production-Inspired Architecture

> "This mirrors how Cloudflare and Akamai work - fast edge caching with async ML-driven optimization."

---

## ğŸ“ˆ Metrics You Can Demonstrate

After running tests:

1. **Cache Hit Rate Improvement:** Show how hit rate increases over time
2. **TTL Adaptation:** Demonstrate TTL changes based on traffic
3. **Pattern Detection:** Show prefetch rules generated from access patterns
4. **Explainability:** Pull up explanations for specific requests
5. **Distributed Load:** Show requests distributed across multiple edges

---

## ğŸ§± Project Structure

```
cdn-simulator/
â”‚
â”œâ”€â”€ docker-compose.yml           # Orchestrates all services
â”‚
â”œâ”€â”€ origin/                      # Origin server
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ nginx.conf
â”‚   â””â”€â”€ static/                  # Static content
â”‚       â”œâ”€â”€ hello.txt
â”‚       â”œâ”€â”€ index.html
â”‚       â”œâ”€â”€ style.css
â”‚       â””â”€â”€ script.js
â”‚
â”œâ”€â”€ edge-enhanced/               # Enhanced edge servers
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ nginx.conf              # Caching config
â”‚   â”œâ”€â”€ log_sender.py           # Sends logs to monitoring
â”‚   â””â”€â”€ entrypoint.sh
â”‚
â”œâ”€â”€ load-balancer/               # Load balancer
â”‚   â””â”€â”€ nginx.conf
â”‚
â”œâ”€â”€ monitoring/                  # Log aggregation service
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ server.py
â”‚
â”œâ”€â”€ control-plane/genai-engine/  # AI control plane
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ main.py                 # Main engine
â”‚   â”œâ”€â”€ engines/
â”‚   â”‚   â”œâ”€â”€ ttl_optimizer.py    # TTL optimization
â”‚   â”‚   â”œâ”€â”€ prefetch_analyzer.py # Prefetch analysis
â”‚   â”‚   â””â”€â”€ explainability.py   # Explainability
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ log_collector.py    # Fetch logs
â”‚   â”‚   â””â”€â”€ config_manager.py   # Manage config
â”‚   â””â”€â”€ api/
â”‚       â””â”€â”€ routes.py           # API endpoints
â”‚
â”œâ”€â”€ api-gateway/                 # Unified API
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ gateway.py              # API gateway + dashboard
â”‚
â””â”€â”€ README.md                    # This file
```

---

## ğŸ‰ What Makes This Project Stand Out

### 1. Production-Inspired Design

âœ… Mirrors real CDN architectures (Cloudflare, Akamai)  
âœ… Control plane / data plane separation  
âœ… Asynchronous AI analysis

### 2. Unique Features

âœ… Explainability layer (rare in CDNs)  
âœ… Adaptive TTL optimization  
âœ… Pattern-based prefetching

### 3. Interview-Ready

âœ… Clear talking points  
âœ… Demonstrable metrics  
âœ… Comprehensive documentation

### 4. Technical Depth

âœ… Multi-container orchestration  
âœ… Log aggregation pipeline  
âœ… AI-driven decision making  
âœ… RESTful API design

---

## ğŸ”® Future Enhancements

- [ ] Geographic routing based on client location
- [ ] Real-time cache invalidation
- [ ] ML model training for better predictions
- [ ] WebSocket for live dashboard updates
- [ ] Prometheus metrics integration
- [ ] Grafana dashboards
- [ ] A/B testing different cache strategies

---

## ğŸ“ License

MIT License - Feel free to use this for learning and interviews!

---

## ğŸ™ Acknowledgments

This project demonstrates real-world CDN concepts inspired by:

- Cloudflare's edge network architecture
- Akamai's adaptive optimization
- Modern control plane/data plane separation
- Production ML/AI integration patterns

---

**Built with â¤ï¸ to demonstrate production-grade system design**

**Perfect for:** System design interviews â€¢ Portfolio projects â€¢ Learning CDN architecture â€¢ Understanding AI/ML integration in infrastructure
